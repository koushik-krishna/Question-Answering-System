{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RP58SmukKTF7"
   },
   "outputs": [],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet tensorflow-hub\n",
    "!pip3 install --quiet seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "iOLXAl8tKDhS",
    "outputId": "3d1a706a-9ba4-4093-db51-06db0475dfe4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GJBv0y7TAKN"
   },
   "source": [
    "# Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUcVdRCSKrZV"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "6himfVaOKrlh",
    "outputId": "02259311-7377-444d-a50e-90bdf39aa551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for: Obama\n",
      "Embedding size: 512\n",
      "Embedding: [-0.0025737364776432514, -0.00893967691808939, -0.025933973491191864, ...]\n",
      "\n",
      "Embedding for: Trump\n",
      "Embedding size: 512\n",
      "Embedding: [0.012550230138003826, 0.012630279175937176, -0.03289252519607544, ...]\n",
      "\n",
      "Embedding for: Who is a republican\n",
      "Embedding size: 512\n",
      "Embedding: [-0.012981751002371311, 0.031171444803476334, -0.033408023416996, ...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Compute a representation for each message, showing various lengths supported.\n",
    "word = \"Obama\"\n",
    "sentence = \"Trump\"\n",
    "paragraph = \"Who is a republican\"\n",
    "messages = [word, sentence, paragraph]\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "\n",
    "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "    print(\"Embedding for: {}\".format(messages[i]))\n",
    "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "    message_embedding_snippet = \", \".join(\n",
    "        (str(x) for x in message_embedding[:3]))\n",
    "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "2dWaUevKMlI7",
    "outputId": "16eb6a09-b705-49e9-e4ae-f3f8c08af158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Obama\n",
      "Embedding size: 512\n",
      "Embedding: [-0.002573722740635276, -0.00893965270370245, -0.02593396231532097, ...]\n",
      "\n",
      "Message: served as president of USA\n",
      "Embedding size: 512\n",
      "Embedding: [0.013818084262311459, 0.010030988603830338, -0.05411097779870033, ...]\n",
      "\n",
      "Message: Trump\n",
      "Embedding size: 512\n",
      "Embedding: [0.01255027111619711, 0.012630279175937176, -0.032892510294914246, ...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Compute a representation for each message, showing various lengths supported.\n",
    "entity = \"Obama\"\n",
    "question = \"served as president of USA\"\n",
    "paragraph = \"Trump\"\n",
    "messages = [entity, question, paragraph]\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "\n",
    "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "    print(\"Message: {}\".format(messages[i]))\n",
    "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "    message_embedding_snippet = \", \".join(\n",
    "        (str(x) for x in message_embedding[:3]))\n",
    "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uX_Zeeg51UO3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "nNVIc98s2hlA",
    "outputId": "d28f5ec9-43f1-4289-c59f-c49496a1cedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: who is politician\n",
      "A: Obama\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Compute a representation for each message, showing various lengths supported.\n",
    "entity1 = \"Obama\"\n",
    "entity2 = \"Beyonce\"\n",
    "question = \"who is politician\"\n",
    "messages = [entity1, entity2, question]\n",
    "\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "  dist1 = distance.euclidean(message_embeddings[0],message_embeddings[2])\n",
    "  dist2 = distance.euclidean(message_embeddings[1],message_embeddings[2])\n",
    "  print(\"Q:\",question)\n",
    "  if(dist1 < dist2):\n",
    "    answer = entity1\n",
    "  else:\n",
    "    answer = entity2\n",
    "  print(\"A:\",answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Ljvpuyg83LNT",
    "outputId": "a8eb6ed7-3d59-4f32-8189-366ce5859136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: who was president\n",
      "A: Obama\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Compute a representation for each message, showing various lengths supported.\n",
    "entity1 = \"Obama\"\n",
    "entity2 = \"Beyonce\"\n",
    "question = \"who was president\"\n",
    "messages = [entity1, entity2, question]\n",
    "\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "  dist1 = distance.euclidean(message_embeddings[0],message_embeddings[2])\n",
    "  dist2 = distance.euclidean(message_embeddings[1],message_embeddings[2])\n",
    "  print(\"Q:\",question)\n",
    "  if(dist1 < dist2):\n",
    "    answer = entity1\n",
    "  else:\n",
    "    answer = entity2\n",
    "  print(\"A:\",answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "HYiJs5593n8K",
    "outputId": "eb09de20-9e4b-43f4-a41f-3ef36698d735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: who is musician\n",
      "A: Beyonce\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Compute a representation for each message, showing various lengths supported.\n",
    "entity1 = \"Obama\"\n",
    "entity2 = \"Beyonce\"\n",
    "question = \"who is musician\"\n",
    "messages = [entity1, entity2, question]\n",
    "\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "  dist1 = distance.euclidean(message_embeddings[0],message_embeddings[2])\n",
    "  dist2 = distance.euclidean(message_embeddings[1],message_embeddings[2])\n",
    "  print(\"Q:\",question)\n",
    "  if(dist1 < dist2):\n",
    "    answer = entity1\n",
    "  else:\n",
    "    answer = entity2\n",
    "  print(\"A:\",answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "YLF7YoTS3xMB",
    "outputId": "2c7981fc-3220-4800-c767-eab133d39e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: who played Tennis\n",
      "A: Roger Federer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Compute a representation for each message, showing various lengths supported.\n",
    "entity1 = \"Sachin Tendulkar\"\n",
    "entity2 = \"Roger Federer\"\n",
    "question = \"who played Tennis\"\n",
    "messages = [entity1, entity2, question]\n",
    "\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "  dist1 = distance.euclidean(message_embeddings[0],message_embeddings[2])\n",
    "  dist2 = distance.euclidean(message_embeddings[1],message_embeddings[2])\n",
    "  print(\"Q:\",question)\n",
    "  if(dist1 < dist2):\n",
    "    answer = entity1\n",
    "  else:\n",
    "    answer = entity2\n",
    "  print(\"A:\",answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "pG-6syxu5N-3",
    "outputId": "942ce243-5d13-494d-8e55-51e9ccfd0d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: who is from America\n",
      "A: Trump\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Compute a representation for each message, showing various lengths supported.\n",
    "entity1 = \"Modi\"\n",
    "entity2 = \"Trump\"\n",
    "question = \"who is from America\"\n",
    "messages = [entity1, entity2, question]\n",
    "\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "  dist1 = distance.euclidean(message_embeddings[0],message_embeddings[2])\n",
    "  dist2 = distance.euclidean(message_embeddings[1],message_embeddings[2])\n",
    "  print(\"Q:\",question)\n",
    "  if(dist1 < dist2):\n",
    "    answer = entity1\n",
    "  else:\n",
    "    answer = entity2\n",
    "  print(\"A:\",answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOARRXl66fz4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCNEahRdJk1P"
   },
   "source": [
    "# PRE TRAINED BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "3QXU-w_51AdI",
    "outputId": "a0555728-f4fc-483f-f8ec-c234eed3fe99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
      "Collecting regex\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n",
      "\u001b[K     |████████████████████████████████| 675kB 8.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.32)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.32)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (1.12.0)\n",
      "Building wheels for collected packages: regex\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=609181 sha256=1c31fc98de5caa5e8d4d59e3f979b906dffff605d162ae6c5fcca79ee9011b10\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n",
      "Successfully built regex\n",
      "Installing collected packages: regex, pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.12.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hmr2cBfZ1E7l",
    "outputId": "e5b4dbaf-55ea-4861-d4e2-96fc9451c1b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 4509092.02B/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FMZ0Aglv1IZj",
    "outputId": "40b75910-931b-4091-8deb-91b7dd131ed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "sBdZIrOh7RYh",
    "outputId": "8be1727a-d7ab-4e6b-b837-40551dd6af58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5wRUwMyg_ZW"
   },
   "outputs": [],
   "source": [
    "fp = open(\"fed.txt\", \"r\")\n",
    "entity = \"federer\"\n",
    "indexes = []\n",
    "for line in fp:\n",
    "    if(entity in line):\n",
    "      # print(line)\n",
    "      text = line\n",
    "      marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "      # Split the sentence into tokens.\n",
    "      tokenized_text = tokenizer.tokenize(marked_text)\n",
    "      # print(tokenized_text)\n",
    "      coutner = 0\n",
    "      for tkn in tokenized_text:\n",
    "        if(tkn == entity):\n",
    "          indexes.append(coutner)\n",
    "          break\n",
    "        coutner += 1\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_tiEj8FyhwpS",
    "outputId": "ca87ad9e-22a2-4b37-99ac-ee126b9c03f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "location in line is  1\n",
      "57\n",
      "57\n",
      "location in line is  5\n",
      "23\n",
      "23\n",
      "location in line is  1\n",
      "78\n",
      "78\n",
      "location in line is  2\n",
      "23\n",
      "23\n",
      "location in line is  1\n",
      "41\n",
      "41\n",
      "location in line is  1\n",
      "23\n",
      "23\n",
      "location in line is  6\n",
      "19\n",
      "19\n",
      "location in line is  7\n",
      "19\n",
      "19\n",
      "location in line is  2\n",
      "25\n",
      "25\n",
      "location in line is  4\n",
      "49\n",
      "49\n",
      "location in line is  19\n",
      "20\n",
      "20\n",
      "location in line is  4\n",
      "25\n",
      "25\n",
      "location in line is  5\n",
      "31\n",
      "31\n",
      "location in line is  11\n",
      "40\n",
      "40\n",
      "location in line is  22\n",
      "27\n",
      "27\n",
      "location in line is  1\n",
      "45\n",
      "45\n",
      "location in line is  9\n",
      "24\n",
      "24\n",
      "location in line is  1\n",
      "38\n",
      "38\n",
      "location in line is  6\n",
      "28\n",
      "28\n",
      "location in line is  5\n",
      "38\n",
      "38\n",
      "location in line is  12\n",
      "25\n",
      "25\n",
      "location in line is  6\n",
      "34\n",
      "34\n",
      "location in line is  1\n",
      "39\n",
      "39\n",
      "location in line is  2\n",
      "64\n",
      "64\n",
      "location in line is  1\n",
      "24\n",
      "24\n",
      "location in line is  1\n",
      "34\n",
      "34\n",
      "location in line is  1\n",
      "16\n",
      "16\n",
      "location in line is  1\n",
      "31\n",
      "31\n",
      "location in line is  1\n",
      "29\n",
      "29\n",
      "location in line is  1\n",
      "37\n",
      "37\n",
      "location in line is  1\n",
      "19\n",
      "19\n",
      "location in line is  4\n",
      "23\n",
      "23\n",
      "location in line is  1\n",
      "32\n",
      "32\n",
      "location in line is  24\n",
      "54\n",
      "54\n",
      "location in line is  1\n",
      "23\n",
      "23\n",
      "location in line is  1\n",
      "19\n",
      "19\n",
      "location in line is  4\n",
      "47\n",
      "47\n",
      "location in line is  4\n",
      "29\n",
      "29\n",
      "location in line is  14\n",
      "8\n",
      "8\n",
      "location in line is  1\n",
      "30\n",
      "30\n",
      "location in line is  14\n",
      "23\n",
      "23\n",
      "location in line is  15\n",
      "32\n",
      "32\n",
      "location in line is  28\n",
      "45\n",
      "45\n",
      "location in line is  1\n",
      "24\n",
      "24\n",
      "location in line is  20\n",
      "26\n",
      "26\n",
      "location in line is  2\n",
      "20\n",
      "20\n",
      "location in line is  16\n",
      "29\n",
      "29\n",
      "location in line is  8\n",
      "32\n",
      "32\n",
      "location in line is  1\n",
      "22\n",
      "22\n",
      "location in line is  1\n",
      "30\n",
      "30\n",
      "location in line is  2\n",
      "18\n",
      "18\n",
      "location in line is  6\n",
      "19\n",
      "19\n",
      "location in line is  4\n",
      "27\n",
      "27\n",
      "location in line is  3\n",
      "31\n",
      "31\n",
      "location in line is  19\n",
      "18\n",
      "18\n",
      "location in line is  2\n",
      "26\n",
      "26\n",
      "location in line is  14\n",
      "25\n",
      "25\n",
      "location in line is  6\n"
     ]
    }
   ],
   "source": [
    "fp = open(\"fed.txt\", \"r\")\n",
    "entity = \"federer\"\n",
    "resultant_vectors_linewise=[]\n",
    "line_number = 0\n",
    "for line in fp:\n",
    "  text = line\n",
    "  if(entity in line):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    # Split the sentence into tokens.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    # Load pre-trained model (weights)\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "      encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "    token_vecs_sum = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "    # print(token_embeddings)\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Sum the vectors from the last four layers.\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "        \n",
    "        # Use `sum_vec` to represent `token`.\n",
    "        token_vecs_sum.append(sum_vec)\n",
    "\n",
    "    print(len(token_embeddings))\n",
    "    print(len(token_vecs_sum))\n",
    "    # resultant_vectors_linewise.append(token_vecs_sum[line_number])\n",
    "    entity_location_in_line = indexes[line_number]\n",
    "    print(\"location in line is \",entity_location_in_line)\n",
    "    resultant_vectors_linewise.append(token_vecs_sum[entity_location_in_line])\n",
    "    line_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vTj4P-XZk0B5",
    "outputId": "4c5ba719-62f0-4306-df1f-2136598e4127"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 197,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resultant_vectors_linewise[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8qcuEvtokMA"
   },
   "outputs": [],
   "source": [
    "fed_mean = torch.mean(torch.stack(resultant_vectors_linewise),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2R8cdbCKokaX",
    "outputId": "490b9dc8-d618-4abe-c233-3b00675c6195"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 199,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aErejhL98NK9",
    "outputId": "cad9c4eb-4464-4e53-be9a-ae1918c89723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 9, 1, 5, 15, 1, 13, 1, 1, 4, 1, 1, 1, 1, 4, 3, 2, 11, 3, 4, 1, 1, 5, 4, 5, 1, 1, 16, 1, 1, 8, 16, 14, 11, 1, 4, 10, 20, 19, 21, 4, 12, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "beyoncefp = open(\"beyonce.txt\", \"r\")\n",
    "entity = \"beyonce\"\n",
    "indexes = []\n",
    "for line in beyoncefp:\n",
    "    if(entity in line):\n",
    "      # print(line)\n",
    "      text = line\n",
    "      marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "      # Split the sentence into tokens.\n",
    "      tokenized_text = tokenizer.tokenize(marked_text)\n",
    "      # print(tokenized_text)\n",
    "      coutner = 0\n",
    "      for tkn in tokenized_text:\n",
    "        # print(tkn)\n",
    "        # print(entity)\n",
    "        if(tkn.lower() == entity.lower()):\n",
    "          indexes.append(coutner)\n",
    "          break\n",
    "        coutner += 1\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "F8dsmv2i8NIm",
    "outputId": "f74a79c7-5906-4ec1-bc63-0b983285a82d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "location in line is  1\n",
      "22\n",
      "22\n",
      "location in line is  9\n",
      "31\n",
      "31\n",
      "location in line is  1\n",
      "59\n",
      "59\n",
      "location in line is  5\n",
      "62\n",
      "62\n",
      "location in line is  15\n",
      "81\n",
      "81\n",
      "location in line is  1\n",
      "35\n",
      "35\n",
      "location in line is  13\n",
      "22\n",
      "22\n",
      "location in line is  1\n",
      "29\n",
      "29\n",
      "location in line is  1\n",
      "27\n",
      "27\n",
      "location in line is  4\n",
      "39\n",
      "39\n",
      "location in line is  1\n",
      "46\n",
      "46\n",
      "location in line is  1\n",
      "20\n",
      "20\n",
      "location in line is  1\n",
      "30\n",
      "30\n",
      "location in line is  1\n",
      "37\n",
      "37\n",
      "location in line is  4\n",
      "37\n",
      "37\n",
      "location in line is  3\n",
      "31\n",
      "31\n",
      "location in line is  2\n",
      "23\n",
      "23\n",
      "location in line is  11\n",
      "17\n",
      "17\n",
      "location in line is  3\n",
      "26\n",
      "26\n",
      "location in line is  4\n",
      "8\n",
      "8\n",
      "location in line is  1\n",
      "27\n",
      "27\n",
      "location in line is  1\n",
      "31\n",
      "31\n",
      "location in line is  5\n",
      "72\n",
      "72\n",
      "location in line is  4\n",
      "46\n",
      "46\n",
      "location in line is  5\n",
      "30\n",
      "30\n",
      "location in line is  1\n",
      "15\n",
      "15\n",
      "location in line is  1\n",
      "32\n",
      "32\n",
      "location in line is  16\n",
      "35\n",
      "35\n",
      "location in line is  1\n",
      "18\n",
      "18\n",
      "location in line is  1\n",
      "16\n",
      "16\n",
      "location in line is  8\n",
      "49\n",
      "49\n",
      "location in line is  16\n",
      "28\n",
      "28\n",
      "location in line is  14\n",
      "25\n",
      "25\n",
      "location in line is  11\n",
      "33\n",
      "33\n",
      "location in line is  1\n",
      "42\n",
      "42\n",
      "location in line is  4\n",
      "17\n",
      "17\n",
      "location in line is  10\n",
      "26\n",
      "26\n",
      "location in line is  20\n",
      "42\n",
      "42\n",
      "location in line is  19\n",
      "37\n",
      "37\n",
      "location in line is  21\n",
      "33\n",
      "33\n",
      "location in line is  4\n",
      "41\n",
      "41\n",
      "location in line is  12\n",
      "23\n",
      "23\n",
      "location in line is  1\n",
      "35\n",
      "35\n",
      "location in line is  1\n"
     ]
    }
   ],
   "source": [
    "beyoncefp = open(\"beyonce.txt\", \"r\")\n",
    "entity = \"beyonce\"\n",
    "resultant_vectors_linewise=[]\n",
    "line_number = 0\n",
    "for line in beyoncefp:\n",
    "  if(entity in line):\n",
    "    text = line\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    # Split the sentence into tokens.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    # Load pre-trained model (weights)\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "      encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "    token_vecs_sum = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "    # print(token_embeddings)\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Sum the vectors from the last four layers.\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "        \n",
    "        # Use `sum_vec` to represent `token`.\n",
    "        token_vecs_sum.append(sum_vec)\n",
    "\n",
    "    print(len(token_embeddings))\n",
    "    print(len(token_vecs_sum))\n",
    "    # resultant_vectors_linewise.append(token_vecs_sum[line_number])\n",
    "    entity_location_in_line = indexes[line_number]\n",
    "    print(\"location in line is \",entity_location_in_line)\n",
    "    resultant_vectors_linewise.append(token_vecs_sum[entity_location_in_line])\n",
    "    line_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmTWPUy68NFc"
   },
   "outputs": [],
   "source": [
    "beyonce_mean = torch.mean(torch.stack(resultant_vectors_linewise),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWbWbyEr8NBd"
   },
   "outputs": [],
   "source": [
    "bl = beyonce_mean.tolist()\n",
    "fl = fed_mean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXel9znPVUSV"
   },
   "outputs": [],
   "source": [
    "sl = singer_rep.tolist()\n",
    "tl = tennis_rep.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwJ7obun1nIq"
   },
   "source": [
    "# Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDvCAfyPBG_P"
   },
   "outputs": [],
   "source": [
    "federer = fed_mean\n",
    "beyonce = beyonce_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Uy1N3ZfOAnhR",
    "outputId": "580dec3c-2b17-4188-ba4c-b45d9b342eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 4.9902e-02, -4.0830e+00,  1.0270e+00, -2.8526e-01,  3.0566e+00,\n",
       "         1.0475e+00,  3.1991e+00, -5.1565e-01, -1.2429e+00, -2.1176e+00,\n",
       "        -4.3403e-01,  1.1588e+00,  2.7612e+00, -1.2453e+00, -2.6644e+00,\n",
       "         4.2172e+00,  2.2009e+00,  1.0669e+00,  1.8090e+00,  8.3090e-01,\n",
       "         2.8399e+00,  3.6855e+00, -2.0258e+00, -2.3690e+00,  1.8940e+00,\n",
       "        -5.9977e-01, -1.9382e+00,  1.1356e+00,  1.5524e+00,  1.9413e+00,\n",
       "         2.0788e+00, -2.5270e+00,  3.5894e+00,  3.9923e+00,  7.6767e-01,\n",
       "         1.1285e+00, -7.1131e-01, -8.9193e-01,  4.3804e-01, -3.8070e+00,\n",
       "        -3.3846e+00, -2.2448e+00, -2.7595e+00,  1.9421e+00,  3.8734e+00,\n",
       "        -2.9131e+00,  1.4569e+00,  3.0655e+00,  4.4835e+00, -1.0595e+00,\n",
       "        -1.2438e+00, -3.8556e-01, -1.1066e-01, -4.4607e-01, -1.3543e+00,\n",
       "         1.5691e+00,  1.7431e+00, -2.9641e+00,  1.2741e+00,  9.4096e-01,\n",
       "        -4.3100e-01,  4.1004e-01, -6.0843e-01, -3.6953e+00,  1.3760e+00,\n",
       "        -1.6058e+00,  2.5915e+00,  2.6663e+00, -2.1226e+00, -2.5194e-01,\n",
       "        -4.4880e+00,  9.8720e-01, -5.3944e+00, -2.1859e+00, -2.4717e+00,\n",
       "        -7.7886e-01, -2.3415e+00,  2.0254e+00,  9.4419e-01,  1.9913e+00,\n",
       "         9.0750e-01, -7.8928e-01,  1.2948e+00,  2.0115e+00, -3.0456e+00,\n",
       "        -1.7735e+00, -6.7096e-01, -6.3358e-01,  1.5089e+00, -3.7303e+00,\n",
       "        -5.8338e-01,  6.6427e-01, -2.8259e-01,  2.4460e-01, -2.9602e+00,\n",
       "         3.0015e+00,  2.3265e-01, -1.1432e+00, -1.0293e+00, -5.6163e-01,\n",
       "         2.5002e+00, -3.3111e+00, -3.4800e+00, -6.6336e-01, -8.2228e-01,\n",
       "        -6.3643e-01, -5.6697e-01,  7.5577e-01, -2.0666e-01, -1.1297e+00,\n",
       "        -1.0901e+00,  2.2447e+00,  1.1158e+00,  1.6789e+00,  2.9843e-01,\n",
       "        -9.6070e-02,  6.7196e-01,  2.4330e+00, -4.4622e+00,  7.8101e-01,\n",
       "         8.1096e-01,  1.4310e+00, -2.5830e-01,  3.0237e+00, -8.5236e-01,\n",
       "         1.7820e-01,  5.0140e+00,  1.8019e+00, -3.6432e+00,  7.0380e-01,\n",
       "         1.5181e+00, -9.6474e-01, -1.3089e+00, -4.2599e+00, -3.8623e+00,\n",
       "        -2.8889e+00,  1.5242e+00,  1.8671e+00,  2.7906e+00,  1.4199e+00,\n",
       "        -2.2035e+00,  3.9602e+00, -1.1861e+00, -1.4136e+00,  1.3623e+00,\n",
       "         1.2405e+00,  3.5202e-01,  2.0959e+00, -6.8830e-01, -1.5049e-01,\n",
       "         1.3897e+00,  4.1770e-01, -3.3804e-01, -5.6893e+00,  2.3537e+00,\n",
       "        -1.1802e+00,  1.4079e-01,  3.3696e-01,  1.1928e+00, -3.4671e-01,\n",
       "         1.2249e+00,  1.7705e+00,  6.2044e-01,  2.3297e+00, -1.1629e+00,\n",
       "         4.9211e+00, -2.4318e-01,  1.8439e+00, -6.7219e-01, -5.5573e+00,\n",
       "        -3.2362e+00,  1.3101e+00, -3.9960e+00,  1.6758e+00, -8.3785e-01,\n",
       "         1.7834e+00,  9.4411e-01,  2.0913e+00,  1.1585e+00,  1.4520e+00,\n",
       "        -1.0296e+00,  3.5485e+00,  3.3171e+00, -7.8026e-01,  2.0784e+00,\n",
       "         1.5149e+00,  1.1305e+00,  9.2464e-01, -2.8005e+00, -2.1892e+00,\n",
       "        -8.6726e-01, -3.3853e+00, -4.5487e-02,  1.1219e+00, -1.1658e+00,\n",
       "         8.2210e-01, -1.4836e+00,  1.5871e-01, -9.6001e-01, -6.7488e-01,\n",
       "         1.2257e+00,  5.6053e-01,  1.6933e+00, -3.8477e+00, -4.8754e+00,\n",
       "         3.2131e+00, -9.1847e-01, -1.0089e+00, -1.3305e+00,  4.5404e+00,\n",
       "         2.3303e-01, -4.4762e+00,  2.7975e+00, -6.1609e-01,  5.6515e-01,\n",
       "        -2.0829e+00, -3.8983e+00, -2.9032e+00, -1.1994e+00,  5.1710e-01,\n",
       "         2.6134e-02,  4.4137e+00, -2.3162e+00, -1.5740e+00,  1.1915e+00,\n",
       "         2.7319e+00, -1.3697e+00,  8.4655e-01, -2.5089e+00, -2.0280e+00,\n",
       "        -5.7358e-01,  2.0178e+00,  1.6841e+00, -2.1826e+00, -1.3294e+00,\n",
       "        -3.0572e-01,  1.9930e+00, -1.4834e+00, -1.5279e+00, -2.2636e+00,\n",
       "        -2.2219e+00, -2.6104e+00, -1.0126e+00,  1.6056e-01, -1.8935e+00,\n",
       "         5.5140e-01, -3.0343e+00, -5.8491e-01,  8.8909e-02,  3.3116e-01,\n",
       "        -1.6765e+00,  8.8265e+00,  3.2391e+00,  3.8221e-01,  4.1661e+00,\n",
       "        -4.3891e-01,  1.9901e+00,  1.9325e+00,  2.4582e+00,  1.6009e+00,\n",
       "         5.8408e-01,  2.7322e+00,  2.8131e+00, -2.1183e-01,  2.9132e+00,\n",
       "        -5.1702e+00,  7.6798e-01,  2.8199e+00,  1.9620e-01,  2.6808e+00,\n",
       "         7.9322e-01,  3.8918e-02, -6.7664e-01,  7.8074e-02, -2.4635e+00,\n",
       "         1.0872e+00,  5.6741e-02, -2.6809e+00,  2.2781e+00, -3.4354e+00,\n",
       "         1.4976e+00,  5.3598e+00,  1.6487e+00, -4.7198e+00,  1.5385e+00,\n",
       "        -7.5921e-01, -1.7408e+00, -2.4219e+00, -9.8947e-01,  5.3001e-02,\n",
       "        -9.8248e-01,  1.5895e-01, -2.6933e+00, -3.5298e+00,  2.6147e+00,\n",
       "        -2.0652e-01,  1.7322e+00,  5.8093e-01, -7.7163e-01,  8.7304e-01,\n",
       "        -1.7239e+00,  2.5067e+00,  4.7982e+00, -3.3265e-01, -5.5326e+00,\n",
       "        -1.4146e+00,  1.3884e+00, -4.2202e-01, -1.0899e+01,  3.4165e+00,\n",
       "         5.1195e-01, -2.3629e+00, -1.0488e+00, -1.9688e+00,  1.0168e+00,\n",
       "        -1.0906e+00,  7.8538e-01, -1.7534e+00,  5.0786e-01, -6.0603e-02,\n",
       "        -7.7559e-01,  1.3055e+00, -7.4917e-01,  1.8606e-01,  1.5568e+00,\n",
       "         1.0889e+00,  1.7330e+00,  3.2776e+00, -6.1962e-01, -3.0921e-01,\n",
       "        -1.7720e-01,  2.4211e-02,  7.5352e-01, -7.6235e-01, -3.6773e+00,\n",
       "        -4.2199e-01,  6.6230e-02, -1.0396e+00,  7.1950e-02, -1.9419e+00,\n",
       "        -1.8680e-01, -8.9459e-01,  1.2302e-01,  3.3968e+00,  1.8844e-02,\n",
       "        -2.4299e+00, -2.0737e+00, -2.3398e+00, -6.8751e-01,  7.7252e-01,\n",
       "         7.5762e-01,  2.9720e+00,  3.4213e+00, -6.8954e-01,  1.0939e+00,\n",
       "        -4.4694e-01, -5.6663e-01,  5.5715e-01,  1.5385e+00,  9.5961e-01,\n",
       "         1.0684e+00, -5.4915e+00,  8.1583e-01, -1.5906e+00, -1.9344e-01,\n",
       "        -2.5066e+00, -1.9190e+00, -1.5028e+00, -3.2827e+00, -2.0481e+00,\n",
       "        -1.6944e-02, -8.4848e-01,  5.3537e+00, -1.1808e+00,  5.0631e-01,\n",
       "        -1.1942e+00,  1.0578e+00, -3.7365e+00, -1.3448e+00, -7.9328e-01,\n",
       "        -5.6083e-01, -1.0559e+01, -2.8333e+00, -2.8564e+00,  3.9888e+00,\n",
       "         8.3713e-01,  2.8851e+00, -3.1276e-02, -2.9825e+00,  8.7867e-01,\n",
       "         1.7033e+00,  1.0560e+00, -2.6910e+00,  1.0472e+00,  1.1931e-01,\n",
       "         3.7602e+00, -2.0400e+00, -3.6679e-01,  1.3391e+00, -1.4024e+00,\n",
       "         8.3539e-01, -9.5750e-01, -2.9697e+00, -1.9523e+00,  9.7416e-01,\n",
       "        -1.2651e+00, -6.5837e-01,  4.0367e-01, -2.2480e+00,  1.6381e+00,\n",
       "         2.8360e+00,  2.3397e+00,  8.1067e-01,  2.2337e+00, -4.8303e+00,\n",
       "         2.8994e-01, -2.3084e+00, -5.8475e-01, -1.3123e-01, -5.9345e-01,\n",
       "         1.2593e+00, -3.5754e-01,  1.1668e-01,  1.1937e+00, -8.4529e-01,\n",
       "        -7.5008e-01,  2.7461e+00, -1.0177e+00, -1.8917e+00, -9.4944e-01,\n",
       "        -2.2030e+00,  5.0338e-01, -6.8747e-02,  5.3587e-01, -1.6808e+00,\n",
       "         4.0108e+00,  7.1556e-02, -1.6125e+00, -5.5202e+00, -8.2687e-02,\n",
       "         1.1632e+00, -1.3009e+00,  7.4495e-01, -2.8867e+00,  1.9045e+00,\n",
       "        -7.2612e+00, -4.9477e+00,  8.1021e-01, -7.7630e-01, -1.1984e+00,\n",
       "        -4.6829e-01, -2.3598e+00,  2.2720e+00, -3.4534e-01, -5.9435e-01,\n",
       "         1.9855e+00,  3.0048e-02,  4.1183e+00, -1.3760e+00, -2.3546e+00,\n",
       "        -3.4156e-01,  1.5234e+00,  4.5978e+00,  9.4528e-01,  2.3812e+00,\n",
       "        -1.8944e+00, -7.0183e-01, -2.3914e+00, -9.8656e-01,  6.7476e-02,\n",
       "        -3.2281e+00, -2.1242e+00, -1.7558e+00,  5.4564e+00,  2.7420e-01,\n",
       "         8.4769e-01, -1.4317e+00, -2.3013e+00,  2.6679e+00, -2.1659e+00,\n",
       "         5.4068e-01, -2.6194e+00, -7.7615e-01,  1.9344e+00,  1.4698e+00,\n",
       "        -9.6705e-01, -1.8743e+00,  3.6561e+00, -2.7953e+00, -1.1382e-02,\n",
       "         1.9971e+00, -2.8896e+00, -6.9454e-01, -5.8952e-01, -2.8186e+00,\n",
       "         3.4033e+00, -2.0276e+00,  5.1976e+00,  1.7270e+00,  1.9845e+00,\n",
       "        -1.3336e+00,  2.8411e+00,  1.4379e+00, -3.4097e+00,  4.9908e-01,\n",
       "        -1.1054e+00, -1.9817e+00,  1.4841e-01, -1.0316e+00,  1.1849e+00,\n",
       "         2.1495e+00,  2.3073e+00,  4.5440e+00,  2.0125e+00, -1.0041e+00,\n",
       "         1.5892e+00, -2.0964e+00,  3.2581e-01, -3.5922e+00,  6.0782e-01,\n",
       "         2.9742e+00, -1.4584e+00, -1.1849e+00,  1.4543e+00, -1.6606e+00,\n",
       "        -3.1588e+00, -1.1793e+00, -2.9436e+00, -4.6364e+00, -2.3015e+00,\n",
       "         5.4928e-01,  8.1221e-01,  1.1195e+00, -2.4574e+00, -2.7351e+00,\n",
       "         1.6901e+00,  7.1992e-01, -1.4512e+00, -2.4892e+00,  9.9263e-01,\n",
       "        -3.3118e-01,  1.2787e+00,  3.6575e-01, -2.1027e+00, -2.2630e+00,\n",
       "         1.6020e-02,  3.8903e+00,  1.1960e+00, -1.4696e+00, -3.0886e+00,\n",
       "         2.4349e-01, -1.3895e+00,  3.0145e-01, -8.4078e-01,  1.1521e+00,\n",
       "         2.1574e+00, -1.3142e+00,  2.2304e+00,  1.7469e+00,  2.9013e+00,\n",
       "         1.1836e+00, -3.4143e+00, -1.6363e+00, -7.0894e-01, -2.2586e+00,\n",
       "        -3.2788e-01, -1.5647e+00, -1.2235e+00, -1.1133e+00,  3.2568e+00,\n",
       "        -1.3526e-01, -1.1705e+00, -1.7703e+00, -4.9901e-01, -1.5591e+00,\n",
       "         6.7756e-01, -3.3030e-01, -7.9722e-01,  7.2883e-01, -3.2950e+00,\n",
       "        -1.9088e+00,  1.0374e+00,  8.0827e-01, -1.0471e+00, -8.8362e-01,\n",
       "        -3.0500e+00, -2.7341e+00,  5.9209e+00, -2.5884e+00,  3.7231e+00,\n",
       "        -2.9523e+00, -3.5152e+00,  3.0485e+00,  1.8724e+00,  2.4400e-01,\n",
       "         2.6792e+00,  7.0988e-02, -3.5057e+00, -2.1035e+00, -1.7375e+00,\n",
       "        -4.6621e+00,  2.2692e+00, -7.2257e-01, -3.5150e-01,  3.9048e-01,\n",
       "         1.4737e+00,  2.4253e+00, -7.5846e-01, -6.2989e+00,  1.0039e+00,\n",
       "        -8.0953e-01,  1.8057e+00,  1.7569e+00, -9.2348e-01,  3.7959e+00,\n",
       "        -1.9754e+00, -1.5107e+00,  1.2894e+00, -2.5406e+00,  1.1180e+00,\n",
       "        -1.9758e+00,  1.8335e+00,  7.2386e+00,  1.8687e+00,  1.4194e+00,\n",
       "         3.5762e+00, -2.2888e+00,  5.8042e-01,  1.1822e+00, -6.0817e+00,\n",
       "        -2.7813e-01,  2.6956e+00,  2.9185e+00,  2.4130e+00,  6.4730e-01,\n",
       "        -2.0114e-01,  1.6936e+00,  1.6062e+00, -8.7164e-01, -9.2764e-01,\n",
       "         1.8392e+00,  9.9253e-01,  8.3374e-01, -3.0208e+00, -3.0094e+00,\n",
       "         1.2194e+00, -3.6704e+00,  1.0496e+00,  1.6886e+00,  1.9104e+00,\n",
       "        -9.1330e-01,  6.7906e+00, -3.9844e+00,  2.4941e+00, -2.4619e+00,\n",
       "        -1.4577e-01,  7.0896e-01, -8.8730e-02,  1.0390e+00,  9.3124e-01,\n",
       "         3.3581e-01, -3.3358e+00,  3.9053e+00, -8.6431e-01,  1.7050e+00,\n",
       "        -1.7347e+00, -4.2830e-02,  3.7107e-03, -3.0228e+00, -1.3839e+00,\n",
       "         3.3387e+00,  2.4169e+00, -1.5128e+00,  9.2218e-01, -3.6130e+00,\n",
       "        -4.0368e-01,  3.1923e+00,  1.4909e-01, -6.6877e-01,  2.0444e+00,\n",
       "        -1.6361e+00,  1.7485e-01,  2.2671e+00,  1.1277e-01, -3.6211e+00,\n",
       "         2.2381e+00,  8.2350e-01, -1.0831e+00,  2.7807e+00, -2.9131e+00,\n",
       "         1.6015e+00,  1.3628e+00, -1.0428e+00,  1.9461e+00, -5.0464e-01,\n",
       "        -1.9589e+00, -1.6715e+00, -7.4577e-01,  4.1942e+00, -7.5963e-01,\n",
       "         3.9996e+00,  2.8912e-01, -6.6756e-01,  1.2750e+00,  1.4891e+00,\n",
       "         8.6720e-01,  2.5542e+00,  1.9568e+00,  1.2666e+00,  3.4606e-01,\n",
       "        -1.1473e+00,  1.1921e+00,  1.6126e-01, -2.0667e-01, -1.0552e+00,\n",
       "        -2.0297e+00, -2.6547e+00,  6.2738e-01, -3.6076e+00, -3.3222e+00,\n",
       "        -4.7173e-01, -2.8680e+00, -8.8661e-01, -4.7682e-01, -3.9511e-01,\n",
       "         2.6003e+00,  4.0773e-01, -2.4942e+00, -9.5027e-01,  1.6789e+00,\n",
       "         4.3005e-01,  4.4235e+00, -4.6167e+00,  6.2677e+00, -1.4830e+00,\n",
       "         2.4802e+00,  4.9751e+00,  4.7169e-01, -1.1175e+00,  2.0065e+00,\n",
       "        -6.6380e-01, -2.6756e+00,  1.5174e+00, -7.4453e-01,  1.5204e+00,\n",
       "         1.2107e+00, -4.4575e+00, -6.5322e-01, -2.0872e+00, -7.9963e-01,\n",
       "        -2.7750e+00, -1.7448e+00,  7.5545e-01,  6.0142e-01,  6.7326e-02,\n",
       "         1.1180e+00,  5.7604e-01,  3.6307e+00,  2.4157e-01, -1.9921e-01,\n",
       "        -1.7233e+00, -7.9818e-01, -2.1254e+00, -4.3996e+00, -3.9611e-01,\n",
       "        -1.4812e+00,  3.9219e-01, -3.2750e+00])"
      ]
     },
     "execution_count": 270,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(beyonce))\n",
    "print(len(beyonce))\n",
    "beyonce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BphcngYAnY2"
   },
   "outputs": [],
   "source": [
    "\n",
    "text = \"who is singer \"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "  encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "# `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = encoded_layers[11][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QK4MnryKEA7R"
   },
   "outputs": [],
   "source": [
    "question = text\n",
    "question_embedding = sentence_embedding \n",
    "entity1 = \"Federer\"\n",
    "entity2 = \"Beyonce\"\n",
    "d1 = torch.dist(fed_mean, sentence_embedding)\n",
    "d2 = torch.dist(beyonce_mean, sentence_embedding)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FY06o088yyk3"
   },
   "outputs": [],
   "source": [
    "def get_answer(question,entity1,entity2):\n",
    "  d1 = torch.dist(fed_mean, sentence_embedding)\n",
    "  d2 = torch.dist(beyonce_mean, sentence_embedding)\n",
    "  if(d1<d2):\n",
    "    return entity1\n",
    "  else:\n",
    "    return entity2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XDbiQhAC8Ksu",
    "outputId": "c8ecc810-6b2f-41d6-bd08-b6fe91616c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyonce\n"
     ]
    }
   ],
   "source": [
    "question = \"who is singer ?\"\n",
    "entity1 = \"Federer\"\n",
    "entity2 = \"Beyonce\"\n",
    "answer = get_answer(question,entity1,entity2)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NsynkHnsFsU8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "EntityEmbeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
