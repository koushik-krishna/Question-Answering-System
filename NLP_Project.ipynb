{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y14wRQeq8MrL",
        "colab_type": "code",
        "outputId": "cfe459ae-c3a0-4275-987a-fb61fdaca786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from scipy.spatial.distance import cosine\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYhn40j2A2Ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "person = None\n",
        "people_sentences = dict()\n",
        "sentence_list = list()\n",
        "people_list = list()\n",
        "i=0\n",
        "with open(\"/content/drive/My Drive/NLP Data.txt\", 'r', encoding='utf8') as handle:\n",
        "    sentences = handle.readlines()\n",
        "    for sentence in sentences[2:]:\n",
        "        i += 1\n",
        "        sentence = sentence.strip()\n",
        "        if len(sentence)<15:\n",
        "            continue\n",
        "        if '#@#@#' in sentence:\n",
        "            sentence = sentence.strip(' \\n@#')\n",
        "            person = sentence.lower().strip()\n",
        "        else:\n",
        "            sentence = sentence.lower()\n",
        "            if person in sentence:\n",
        "                sentence = sentence.replace(person, 'x')\n",
        "\n",
        "            sentence_list.append(sentence)\n",
        "            people_list.append(person)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkjX3_CzcP3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/random.txt\", 'r', encoding='utf8') as handle:\n",
        "    clean_sentences = list()\n",
        "    sentences = handle.readlines()\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if len(sentence)<15:\n",
        "            continue\n",
        "        clean_sentences.append(sentence)\n",
        "    from random import sample \n",
        "    clean_sentences = sample(clean_sentences, 4500)\n",
        "    sentence_list += clean_sentences\n",
        "    people_list += ['None']*4500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXr89G5_dvcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "people_sentences['Sentence'] = sentence_list\n",
        "people_sentences['Person'] = people_list\n",
        "data = pd.DataFrame.from_dict(people_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h6MINjofrTj",
        "colab_type": "code",
        "outputId": "0e2a0f6d-b909-4dbd-d9cf-d6b3a447605a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "data['Person'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "None         4470\n",
              "jackson      2071\n",
              "dicaprio     1926\n",
              "tendulkar    1164\n",
              "federer      1033\n",
              "gates         983\n",
              "beyonce       890\n",
              "bengio         36\n",
              "Name: Person, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh04AlvHQkJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "data = shuffle(data)\n",
        "data.Person = data.Person.astype('category')\n",
        "\n",
        "test_data = pd.DataFrame()\n",
        "for person in data['Person'].unique():\n",
        "    test_data = test_data.append(data.loc[data['Person'] == person].sample(30))\n",
        "\n",
        "data = data[~data.Sentence.isin(test_data.Sentence)].dropna()\n",
        "train_text = data['Sentence'].tolist()\n",
        "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
        "train_label = np.asarray(pd.get_dummies(data.Person), dtype = np.int8)\n",
        "\n",
        "test_data = shuffle(test_data)\n",
        "test_data.Person = test_data.Person.astype('category')\n",
        "test_text = test_data['Sentence'].tolist()\n",
        "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
        "test_label = np.asarray(pd.get_dummies(test_data.Person), dtype = np.int8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP9t2hBd0Z7M",
        "colab_type": "code",
        "outputId": "bb2db59b-bb04-4537-b121-6273aae42abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12573, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm7DOthI6hHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used for Universal Sentence Encoder sentence embedding generation\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzt3sWZbSI35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used for Universal Sentence Encoder sentence embedding generation\n",
        "def GenUniversalSentenceEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), \n",
        "    \tsignature=\"default\", as_dict=True)[\"default\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU75LOWS4XFO",
        "colab_type": "code",
        "outputId": "3299ea7e-8ed6-418e-cb0a-582de88321c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "source": [
        "# Used for BERT sentence embedding generation\n",
        "!pip install pytorch-pretrained-bert\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.9MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.32)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.32)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=609175 sha256=075fc6ecf4ceb9d2e97a8a334a9c62125e2f27f5992d0f3513a1481b3ffd9c0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.12.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObMMPO0P6rbK",
        "colab_type": "code",
        "outputId": "884f17d8-50f0-4482-834f-9294cd90b4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Used for BERT sentence embedding generation\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:07<00:00, 51698275.88B/s]\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 2667901.95B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0pgFFYB404N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used for BERT sentence embedding generation\n",
        "# @tf.function\n",
        "def BertSentenceEmbedding(text):\n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "    # Split the sentence into tokens.\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "    # Map the token strings to their vocabulary indeces.\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    \n",
        "    # Predict hidden states features for each layer\n",
        "    with torch.no_grad():\n",
        "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
        "    # Concatenate the tensors for all layers. We use `stack` here to\n",
        "    # create a new dimension in the tensor.\n",
        "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "    # `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
        "    # `token_vecs` is a tensor with shape [22 x 768]\n",
        "    token_vecs = encoded_layers[11][0]\n",
        "\n",
        "    # Calculate the average of all 22 token vectors.\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "    return sentence_embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdvSmc9BZZ0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used for BERT sentence embedding generation\n",
        "def return_bert_embeddings_for_text(input_text):\n",
        "    train_embeddings = []\n",
        "    for text in input_text:\n",
        "        text = text[0]\n",
        "        embedding = BertSentenceEmbedding(text)\n",
        "        train_embeddings.append(embedding)\n",
        "    return train_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6ukM5f9e67F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used for BERT sentence embedding generation\n",
        "train_embeddings = return_bert_embeddings_for_text(train_text)\n",
        "train_embeddings = np.array(train_embeddings, dtype=object)[:, np.newaxis]\n",
        "validation_embeddings = return_bert_embeddings_for_text(test_text)\n",
        "validation_embeddings = np.array(validation_embeddings, dtype=object)[:, np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWjgzojFGkT9",
        "colab_type": "code",
        "outputId": "f829ca8a-0e06-447d-863d-e8e5626ff062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Used for BERT sentence embedding generation\n",
        "train_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12609, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9If1pybB-iy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f8359478-fb77-4b5f-e2f6-cb075429f32a"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
        "embedding = layers.Lambda(GenUniversalSentenceEmbedding,\n",
        "\toutput_shape=(None,))(input_text)\n",
        "dense = layers.Dense(300, activation='relu')(embedding)\n",
        "dense = layers.BatchNormalization()(dense)\n",
        "dense = layers.Dropout(0.4)(dense)\n",
        "dense1 = layers.Dense(200, activation='relu')(dense)\n",
        "dense1 = layers.BatchNormalization()(dense1)\n",
        "dense1 = layers.Dropout(0.4)(dense1)\n",
        "dense2 = layers.Dense(100, activation='relu')(dense1)\n",
        "pred = layers.Dense(len(data['Person'].unique()), activation='softmax')(dense2)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "\toptimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io0rlN4sZSd2",
        "colab_type": "code",
        "outputId": "eafb0b98-1083-4474-e877-fa69c6f2e6b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "from keras import backend as K\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  history = model.fit(train_text, \n",
        "            train_label,\n",
        "            validation_data=(test_text, test_label),\n",
        "            epochs=15,\n",
        "            batch_size=32)\n",
        "  model.save_weights('./model.h6')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 12573 samples, validate on 240 samples\n",
            "Epoch 1/15\n",
            "12573/12573 [==============================] - 20s 2ms/sample - loss: 0.6353 - acc: 0.7825 - val_loss: 1.0645 - val_acc: 0.7417\n",
            "Epoch 2/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.4430 - acc: 0.8421 - val_loss: 0.5207 - val_acc: 0.8333\n",
            "Epoch 3/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.3831 - acc: 0.8593 - val_loss: 0.5706 - val_acc: 0.8125\n",
            "Epoch 4/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.3550 - acc: 0.8665 - val_loss: 0.4740 - val_acc: 0.8500\n",
            "Epoch 5/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.3225 - acc: 0.8768 - val_loss: 0.4201 - val_acc: 0.8667\n",
            "Epoch 6/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.3136 - acc: 0.8788 - val_loss: 0.4023 - val_acc: 0.8708\n",
            "Epoch 7/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.3011 - acc: 0.8876 - val_loss: 0.4489 - val_acc: 0.8583\n",
            "Epoch 8/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.2826 - acc: 0.8898 - val_loss: 0.4291 - val_acc: 0.8667\n",
            "Epoch 9/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.2745 - acc: 0.8929 - val_loss: 0.5028 - val_acc: 0.8500\n",
            "Epoch 10/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.2605 - acc: 0.8982 - val_loss: 0.4804 - val_acc: 0.8583\n",
            "Epoch 11/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.2508 - acc: 0.9004 - val_loss: 0.4414 - val_acc: 0.8750\n",
            "Epoch 12/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.2463 - acc: 0.9031 - val_loss: 0.5744 - val_acc: 0.8375\n",
            "Epoch 13/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.2396 - acc: 0.9046 - val_loss: 0.5923 - val_acc: 0.8333\n",
            "Epoch 14/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.2235 - acc: 0.9096 - val_loss: 0.4963 - val_acc: 0.8625\n",
            "Epoch 15/15\n",
            "12573/12573 [==============================] - 17s 1ms/sample - loss: 0.2088 - acc: 0.9145 - val_loss: 0.6028 - val_acc: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py9Nbr1p8eSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used for BERT sentence embedding generation\n",
        "train_embeddings_m = []\n",
        "for embedding in train_embeddings:\n",
        "    train_embeddings_m.append(embedding[0].tolist())\n",
        "validation_embeddings_m = []\n",
        "for embedding in validation_embeddings:\n",
        "    validation_embeddings_m.append(embedding[0].tolist())\n",
        "train_embeddings_m = np.array(train_embeddings_m)\n",
        "validation_embeddings_m = np.array(validation_embeddings_m)\n",
        "train_embeddings_m.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs43xk9rgCOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_text = [\"Who is born in Switzerland ?\", \n",
        "            \"Who is a singer ?\", \n",
        "            \"Who is a dancer ?\",\n",
        "            \"Whose album was on BillBoard ?\",\n",
        "            \"Whose won Turing award ?\",\n",
        "            \"Whose is working in artificial intelligence ?\",\n",
        "            \"Whose is working in machine learning ?\",\n",
        "            \"Who is a Cricketer ?\",\n",
        "            \"Who belongs to India ?\",\n",
        "            \"Who is Rich ?\",\n",
        "            \"Who served Prison Time ?\",\n",
        "            \"Who is in Software Industry ?\",\n",
        "            \"Who is not a singer ?\",\n",
        "            \"Who is a Computer Scientist ?\",\n",
        "            \"Who is Scientist ?\",\n",
        "            \"Who is into the Research ?\",\n",
        "            \"Who sponsored the brand MRF ?\",\n",
        "            \"Who does farming ?\",\n",
        "            \"Who owns a vineyard ?\",\n",
        "            \"Who is famous ?\",\n",
        "            \"Who is Corrupted ?\",\n",
        "            \"Who is an alcoholic ?\",\n",
        "            \"Who grew up in Namibia ?\",\n",
        "            \"Who owns the military ?\",\n",
        "            \"Who is She ?\",\n",
        "            \"Who is Woman ?\",\n",
        "            \"Who is Female ?\",\n",
        "            \"Who plays Tennis ?\",\n",
        "            \"Who is a Movie Star ?\",\n",
        "            \"Who is divorced ?\",\n",
        "            \"Who is dead ?\",\n",
        "            \"Who plays video games ?\",\n",
        "            \"Who played in Rawalpindi ?\",\n",
        "            \"Who is born in Pakistan ?\",\n",
        "            \"Who won Grand Slams ?\",\n",
        "            \"Who is called Master Blaster ?\",\n",
        "            \"Who is member of Rajya Sabha ?\",\n",
        "            \"Who worked with Scorsese ?\",\n",
        "            \"Who worked with Director Scorsese ?\",\n",
        "            \"Who worked with Movie Director Scorsese ?\",\n",
        "            \"Who is an enviromentalist ?\"]\n",
        "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
        "# test_embeddings = return_bert_embeddings_for_text(new_text)\n",
        "# test_embeddings = np.array(test_embeddings, dtype=object)[:, np.newaxis]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yew7_FwpLJI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used for BERT sentence embedding generation\n",
        "test_embeddings_m = []\n",
        "for embedding in test_embeddings:\n",
        "    test_embeddings_m.append(embedding[0].tolist())\n",
        "test_embeddings_m = np.array(test_embeddings_m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdculgeemDvy",
        "colab_type": "code",
        "outputId": "8541703f-d1a3-4bc8-a5ab-1f67a4f1ba1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./model.h6')  \n",
        "  predicts = model.predict(new_text, batch_size=32)\n",
        "\n",
        "categories = data.Person.cat.categories.tolist()\n",
        "predict_logits = predicts.argmax(axis=1)\n",
        "predict_labels = [categories[logit] for logit in predict_logits]\n",
        "for i in range(len(predict_labels)):\n",
        "    print(new_text[i], predict_labels[i])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Who is born in Switzerland ?'] federer\n",
            "['Who is a singer ?'] beyonce\n",
            "['Who is a dancer ?'] jackson\n",
            "['Whose album was on BillBoard ?'] jackson\n",
            "['Whose won Turing award ?'] bengio\n",
            "['Whose is working in artificial intelligence ?'] bengio\n",
            "['Whose is working in machine learning ?'] bengio\n",
            "['Who is a Cricketer ?'] tendulkar\n",
            "['Who belongs to India ?'] None\n",
            "['Who is Rich ?'] gates\n",
            "['Who served Prison Time ?'] jackson\n",
            "['Who is in Software Industry ?'] gates\n",
            "['Who is not a singer ?'] jackson\n",
            "['Who is a Computer Scientist ?'] gates\n",
            "['Who is Scientist ?'] dicaprio\n",
            "['Who is into the Research ?'] gates\n",
            "['Who sponsored the brand MRF ?'] tendulkar\n",
            "['Who does farming ?'] None\n",
            "['Who owns a vineyard ?'] None\n",
            "['Who is famous ?'] dicaprio\n",
            "['Who is Corrupted ?'] None\n",
            "['Who is an alcoholic ?'] None\n",
            "['Who grew up in Namibia ?'] federer\n",
            "['Who owns the military ?'] dicaprio\n",
            "['Who is She ?'] beyonce\n",
            "['Who is Woman ?'] None\n",
            "['Who is Female ?'] None\n",
            "['Who plays Tennis ?'] federer\n",
            "['Who is a Movie Star ?'] dicaprio\n",
            "['Who is divorced ?'] jackson\n",
            "['Who is dead ?'] None\n",
            "['Who plays video games ?'] dicaprio\n",
            "['Who played in Rawalpindi ?'] tendulkar\n",
            "['Who is born in Pakistan ?'] tendulkar\n",
            "['Who won Grand Slams ?'] federer\n",
            "['Who is called Master Blaster ?'] tendulkar\n",
            "['Who is member of Rajya Sabha ?'] tendulkar\n",
            "['Who worked with Scorsese ?'] dicaprio\n",
            "['Who worked with Director Scorsese ?'] dicaprio\n",
            "['Who worked with Movie Director Scorsese ?'] dicaprio\n",
            "['Who is an enviromentalist ?'] dicaprio\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83U0r0EM5iLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}